version: "3.7"

  #/  Lo primero que vemos son algunas variables, es una caracteristica muy vacana y es que puede cojer la configuraci√≥n desde las variables del sistema operativo 
x-airflow-environment: &airflow-environment
  AIRFLOW__CORE__EXECUTOR: LocalExecutor 
  AIRFLOW__CORE__LOAD_EXAMPLES: "True" 
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow 
  AIRFLOW__CORE__FERNET_KEY: FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM= 
  AIRFLOW__DAG_DEFAULT_VIEW: graph 
  #/ Por aca definimos la variable
  AIRFLOW_VAR_EMAIL_PRUEBA: jesus@prueba2.com



#/ Esto esta basado en cuatro contenedores 
services:
  #- Este levanta la db con al contra por defecto que esta en la linea 7
  postgres:
    image: postgres:11.5
    environment:
      POSTGRES_USER: airflow
      POSTGRES_DB: airflow
      POSTGRES_PASSWORD: airflow
  #-1.0 este contenedor init con la imagen de apache/airflow:1.10.10
  init:
    image: apache/airflow:1.10.10
    environment:
      <<: *airflow-environment
    #- 1.1 que depende de la base de posgrest
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./logs:/opt/airflow/logs
    entrypoint: /bin/bash
    #- esto lo que hase es listar los usuario y si no exixten inicia la metadata de la db con un user
    command: >
      -c "airflow list_users || (airflow initdb
      && airflow create_user --role Admin --username airflow --password airflow -e airflow@airflow.com -f airflow -l airflow)"
    restart: on-failure

  #! en el webserver y en el scheduler poner el volumen
  webserver:
    image: apache/airflow:1.10.10
    ports:
      - 9090:8080 
    environment:
      <<: *airflow-environment
    depends_on:
      - init
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./logs:/opt/airflow/logs
      #/ Desde aca creamos un volumen para importar las variables
      - ./variables.json:/otp/airflow/variables.json
    entrypoint: /bin/bash
    #! aca ponemos el comando para importar las variables en el scheduler tambien
    command: -c "airflow variables -i /otp/airflow/variables.json && airflow webserver"
    restart: always
  
  scheduler:
    image: apache/airflow:1.10.10
    environment:
      <<: *airflow-environment
    depends_on:
      - webserver
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./logs:/opt/airflow/logs
      #/ Desde aca creamos un volumen para importar las variables
      - ./variables.json:/otp/airflow/variables.json
    entrypoint: /bin/bash
    #/ aca cambios
    command: -c "airflow variables -i /otp/airflow/variables.json && airflow scheduler"
    restart: always